{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import io \n",
    "import requests\n",
    "import datetime\n",
    "import ondemand\n",
    "from scipy.stats import pearsonr\n",
    "from pandas.io.common import EmptyDataError\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get business days\n",
    "from pandas.tseries.offsets import *\n",
    "daterange1 = pd.date_range('2017-12-01', '2019-01-20', freq=BDay())\n",
    "daterange1 = list(daterange1.strftime('%Y-%m-%d'))\n",
    "holidays = ['2017-12-25', '2018-01-01', '2018-01-15', '2018-02-19', '2018-03-30', '2018-05-28', '2018-07-04', '2018-09-03',\\\n",
    "            '2018-11-22', '2018-12-05', '2018-12-25', '2019-01-01']\n",
    "for each in holidays:\n",
    "    if each in daterange1:\n",
    "        daterange1.remove(each)\n",
    "daterange = daterange1[20:271] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ondemand.websol.barchart.com/getHistory.csv?apikey=OnDemand&symbol={}&type=daily&startDate={}&endDate={}&maxRecords=1000&interval=60&order=asc&sessionFilter=EFK&splits=true&dividends=true&volume=sum&nearby=1&jerq=true&exchange=NYSE%2CAMEX%2CNASDAQ&backAdjust=false&daysToExpiration=1&contractRoll=expiration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for hold-1b day\n",
    "all_res = pd.DataFrame([])\n",
    "small_res = pd.DataFrame([])\n",
    "mid_res = pd.DataFrame([])\n",
    "large_res = pd.DataFrame([])\n",
    "for cap in ['small', 'mid', 'large']:\n",
    "    for date in daterange:\n",
    "        for win in [1, 3]:#should include 1, 3\n",
    "            each = date\n",
    "            each = each[5:]\n",
    "            each = each.replace('-', '')\n",
    "            try:\n",
    "                mydf = pd.read_csv('leaderlist {}/{}_cap/window_{}_day/hold_1b_day/{}_{}_cap_window_{}_hold_1b_detail.csv'.\\\n",
    "                                   format(date, cap, win, each, cap, win))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            if cap == 'small':\n",
    "                small_res = pd.concat([mydf, small_res], sort = False, ignore_index = True)\n",
    "            elif cap == 'mid':\n",
    "                mid_res = pd.concat([mydf, mid_res], sort = False, ignore_index = True)\n",
    "            elif cap == 'large':\n",
    "                large_res = pd.concat([mydf, large_res], sort = False, ignore_index = True)\n",
    "            #all_res = pd.concat([mydf, all_res], sort = False, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for hold_1b\n",
    "#for win-1\n",
    "small_res_win1 = small_res.loc[small_res['window'] == 1]\n",
    "mid_res_win1 = mid_res.loc[mid_res['window'] == 1]\n",
    "large_res_win1 = large_res.loc[large_res['window'] == 1]\n",
    "small_res_win1.to_csv('analysis/hold_1b_day/small_res_win1.csv', index = False)\n",
    "mid_res_win1.to_csv('analysis/hold_1b_day/mid_res_win1.csv', index = False)\n",
    "large_res_win1.to_csv('analysis/hold_1b_day/large_res_win1.csv', index = False)\n",
    "\n",
    "#for win-3\n",
    "small_res_win3 = small_res.loc[small_res['window'] == 3]\n",
    "mid_res_win3 = mid_res.loc[mid_res['window'] == 3]\n",
    "large_res_win3 = large_res.loc[large_res['window'] == 3]\n",
    "small_res_win3.to_csv('analysis/hold_1b_day/small_res_win3.csv', index = False)\n",
    "mid_res_win3.to_csv('analysis/hold_1b_day/mid_res_win3.csv', index = False)\n",
    "large_res_win3.to_csv('analysis/hold_1b_day/large_res_win3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for hold-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.504200e+04\n",
       "mean              inf\n",
       "std               NaN\n",
       "min     -5.500000e-01\n",
       "25%      2.500000e+00\n",
       "50%      4.030000e+00\n",
       "75%      6.350000e+00\n",
       "max               inf\n",
       "Name: actual_pageview_in_std, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res['actual_pageview_in_std'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15042.000000\n",
       "mean        -0.204810\n",
       "std          6.030359\n",
       "min        -84.883721\n",
       "25%         -2.155376\n",
       "50%         -0.133895\n",
       "75%          1.681104\n",
       "max        333.333333\n",
       "Name: pct_change(%), dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res['pct_change(%)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the pct_change(%) group value for small_cap_window1_hold1b\n",
    "#pageviewchange x < 2.5\n",
    "for win in [1, 3]:#include 1, 3\n",
    "    for cap in ['small', 'large', 'mid']:\n",
    "        myres = pd.DataFrame([], index = [0, 1, 2, 3],\\\n",
    "                                                 columns = ['pageview_change_group', 'pct_change(%) < -1(% in samples(total))', \\\n",
    "                                                           '-1 <= pct_change(%) < 0(% in samples(total))', \\\n",
    "                                                            '0 <= pct_change(%) < 1(% in samples(total))', \\\n",
    "                                                            'pct_change(%) >= 1(% in samples(total))', 'samples(total)'])\n",
    "        myres.iloc[0]['pageview_change_group'] = 'x < 2.5'\n",
    "        myres.iloc[1]['pageview_change_group'] = '2.5 <= x < 4'\n",
    "        myres.iloc[2]['pageview_change_group'] = '4 <= x < 6'\n",
    "        myres.iloc[3]['pageview_change_group'] = 'x >= 6'\n",
    "        rawdata = pd.read_csv('analysis/hold_1b_day/{}_res_win{}.csv'.format(cap, win))\n",
    "        raw_0 = rawdata.loc[rawdata['actual_pageview_in_std'] < 2.5]\n",
    "        raw_1 = rawdata.loc[(rawdata['actual_pageview_in_std'] < 4)&(rawdata['actual_pageview_in_std'] >= 2.5)]\n",
    "        raw_2 = rawdata.loc[(rawdata['actual_pageview_in_std'] < 6)&(rawdata['actual_pageview_in_std'] >= 4)]\n",
    "        raw_3 = rawdata.loc[rawdata['actual_pageview_in_std'] >= 6]\n",
    "        myres.iloc[0, 5] = raw_0.shape[0]\n",
    "        myres.iloc[1, 5] = raw_1.shape[0]\n",
    "        myres.iloc[2, 5] = raw_2.shape[0]\n",
    "        myres.iloc[3, 5] = raw_3.shape[0]\n",
    "        raw = dict()\n",
    "        raw[0] = raw_0\n",
    "        raw[1] = raw_1\n",
    "        raw[2] = raw_2\n",
    "        raw[3] = raw_3\n",
    "        for i in range(4):\n",
    "            temp1 = raw[i].loc[raw[i]['pct_change(%)'] < -1]\n",
    "            total = raw[i].shape[0] + 0.00001\n",
    "            myres.iloc[i, 1] = (temp1.shape[0]/total)*100\n",
    "            temp2 = raw[i].loc[(raw[i]['pct_change(%)'] >= -1)&(raw[i]['pct_change(%)'] < 0)]\n",
    "            myres.iloc[i, 2] = (temp2.shape[0]/total)*100\n",
    "            temp3 = raw[i].loc[(raw[i]['pct_change(%)'] >= 0)&(raw[i]['pct_change(%)'] < 1)]\n",
    "            myres.iloc[i, 3] = (temp3.shape[0]/total)*100\n",
    "            temp4 = raw[i].loc[raw[i]['pct_change(%)'] >= 1]\n",
    "            myres.iloc[i, 4] = (temp4.shape[0]/total)*100\n",
    "        if not os.path.exists(os.path.dirname('{}_cap/window_{}_day/hold_1b_day_statistics/'.format(cap, win))):\n",
    "            os.makedirs(os.path.dirname('{}_cap/window_{}_day/hold_1b_day_statistics/'.format(cap, win)))\n",
    "        myres.to_csv('{}_cap/window_{}_day/hold_1b_day_statistics/statistics_{}_cap_window_{}_hold_1b.csv'.format(cap, win, cap, win), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
