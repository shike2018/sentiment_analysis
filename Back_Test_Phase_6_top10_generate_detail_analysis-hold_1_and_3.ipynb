{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import io \n",
    "import requests\n",
    "import datetime\n",
    "import ondemand\n",
    "from scipy.stats import pearsonr\n",
    "from pandas.io.common import EmptyDataError\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get business days\n",
    "from pandas.tseries.offsets import *\n",
    "daterange1 = pd.date_range('2017-12-01', '2019-01-20', freq=BDay())\n",
    "daterange1 = list(daterange1.strftime('%Y-%m-%d'))\n",
    "holidays = ['2017-12-25', '2018-01-01', '2018-01-15', '2018-02-19', '2018-03-30', '2018-05-28', '2018-07-04', '2018-09-03',\\\n",
    "            '2018-11-22', '2018-12-05', '2018-12-25', '2019-01-01']\n",
    "for each in holidays:\n",
    "    if each in daterange1:\n",
    "        daterange1.remove(each)\n",
    "daterange = daterange1[20:271]        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ondemand.websol.barchart.com/getHistory.csv?apikey=OnDemand&symbol={}&type=daily&startDate={}&endDate={}&maxRecords=1000&interval=60&order=asc&sessionFilter=EFK&splits=true&dividends=true&volume=sum&exchange=NYSE%2CAMEX%2CNASDAQ&backAdjust=false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small\n",
      "mid\n",
      "large\n"
     ]
    }
   ],
   "source": [
    "#for hold-1 day\n",
    "all_res = pd.DataFrame([])\n",
    "small_res = pd.DataFrame([])\n",
    "mid_res = pd.DataFrame([])\n",
    "large_res = pd.DataFrame([])\n",
    "for cap in ['small', 'mid', 'large']:\n",
    "    print(cap)\n",
    "    for date in daterange:\n",
    "        for win in [1, 3]:\n",
    "            trading_day = daterange1[daterange1.index(date) + 1]\n",
    "            each = trading_day\n",
    "            each = each[5:]\n",
    "            each = each.replace('-', '')\n",
    "            try:\n",
    "                mydf = pd.read_csv('leaderlist {}/{}_cap/window_{}_day/hold_1_day/{}_{}_cap_window_{}_hold_1_detail.csv'.\\\n",
    "                                   format(date, cap, win, each, cap, win))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            if cap == 'small':\n",
    "                small_res = pd.concat([mydf, small_res], sort = False, ignore_index = True)\n",
    "            elif cap == 'mid':\n",
    "                mid_res = pd.concat([mydf, mid_res], sort = False, ignore_index = True)\n",
    "            elif cap == 'large':\n",
    "                large_res = pd.concat([mydf, large_res], sort = False, ignore_index = True)\n",
    "            #all_res = pd.concat([mydf, all_res], sort = False, ignore_index = True)\n",
    "\n",
    "#for win-1\n",
    "small_res_win1 = small_res.loc[small_res['window'] == 1]\n",
    "mid_res_win1 = mid_res.loc[mid_res['window'] == 1]\n",
    "large_res_win1 = large_res.loc[large_res['window'] == 1]\n",
    "small_res_win1.to_csv('analysis/hold_1_day/small_res_win1.csv', index = False)\n",
    "mid_res_win1.to_csv('analysis/hold_1_day/mid_res_win1.csv', index = False)\n",
    "large_res_win1.to_csv('analysis/hold_1_day/large_res_win1.csv', index = False)\n",
    "#for win-3\n",
    "small_res_win3 = small_res.loc[small_res['window'] == 3]\n",
    "mid_res_win3 = mid_res.loc[mid_res['window'] == 3]\n",
    "large_res_win3 = large_res.loc[large_res['window'] == 3]\n",
    "small_res_win3.to_csv('analysis/hold_1_day/small_res_win3.csv', index = False)\n",
    "mid_res_win3.to_csv('analysis/hold_1_day/mid_res_win3.csv', index = False)\n",
    "large_res_win3.to_csv('analysis/hold_1_day/large_res_win3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small\n",
      "mid\n",
      "large\n"
     ]
    }
   ],
   "source": [
    "#for hold-3 day\n",
    "all_res = pd.DataFrame([])\n",
    "small_res = pd.DataFrame([])\n",
    "mid_res = pd.DataFrame([])\n",
    "large_res = pd.DataFrame([])\n",
    "for cap in ['small', 'mid', 'large']:\n",
    "    print(cap)\n",
    "    for date in daterange:\n",
    "        for win in [1, 3]:\n",
    "            trading_day = daterange1[daterange1.index(date) + 1]\n",
    "            each = trading_day\n",
    "            each = each[5:]\n",
    "            each = each.replace('-', '')\n",
    "            try:\n",
    "                mydf = pd.read_csv('leaderlist {}/{}_cap/window_{}_day/hold_3_day/{}_{}_cap_window_{}_hold_3_detail.csv'.\\\n",
    "                                   format(date, cap, win, each, cap, win))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            if cap == 'small':\n",
    "                small_res = pd.concat([mydf, small_res], sort = False, ignore_index = True)\n",
    "            elif cap == 'mid':\n",
    "                mid_res = pd.concat([mydf, mid_res], sort = False, ignore_index = True)\n",
    "            elif cap == 'large':\n",
    "                large_res = pd.concat([mydf, large_res], sort = False, ignore_index = True)\n",
    "            #all_res = pd.concat([mydf, all_res], sort = False, ignore_index = True)\n",
    "\n",
    "#for win-1\n",
    "small_res_win1 = small_res.loc[small_res['window'] == 1]\n",
    "mid_res_win1 = mid_res.loc[mid_res['window'] == 1]\n",
    "large_res_win1 = large_res.loc[large_res['window'] == 1]\n",
    "small_res_win1.to_csv('analysis/hold_3_day/small_res_win1.csv', index = False)\n",
    "mid_res_win1.to_csv('analysis/hold_3_day/mid_res_win1.csv', index = False)\n",
    "large_res_win1.to_csv('analysis/hold_1_day/large_res_win1.csv', index = False)\n",
    "#for win-3\n",
    "small_res_win3 = small_res.loc[small_res['window'] == 3]\n",
    "mid_res_win3 = mid_res.loc[mid_res['window'] == 3]\n",
    "large_res_win3 = large_res.loc[large_res['window'] == 3]\n",
    "small_res_win3.to_csv('analysis/hold_3_day/small_res_win3.csv', index = False)\n",
    "mid_res_win3.to_csv('analysis/hold_3_day/mid_res_win3.csv', index = False)\n",
    "large_res_win3.to_csv('analysis/hold_3_day/large_res_win3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.504200e+04\n",
       "mean              inf\n",
       "std               NaN\n",
       "min     -5.500000e-01\n",
       "25%      2.500000e+00\n",
       "50%      4.030000e+00\n",
       "75%      6.350000e+00\n",
       "max               inf\n",
       "Name: actual_pageview_in_std, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res['actual_pageview_in_std'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15042.000000\n",
       "mean        -0.204810\n",
       "std          6.030359\n",
       "min        -84.883721\n",
       "25%         -2.155376\n",
       "50%         -0.133895\n",
       "75%          1.681104\n",
       "max        333.333333\n",
       "Name: pct_change(%), dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res['pct_change(%)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the pct_change(%) group value for small_cap_window1_hold1\n",
    "#pageviewchange x < 2.5\n",
    "for hold in [1, 3]:\n",
    "    for win in [1, 3]:#should in clude 1, 3\n",
    "        for cap in ['small', 'large', 'mid']:\n",
    "            myres = pd.DataFrame([], index = [0, 1, 2, 3],\\\n",
    "                                                     columns = ['pageview_change_group', 'pct_change(%) < -1(% in samples(total))', \\\n",
    "                                                               '-1 <= pct_change(%) < 0(% in samples(total))', \\\n",
    "                                                                '0 <= pct_change(%) < 1(% in samples(total))', \\\n",
    "                                                                'pct_change(%) >= 1(% in samples(total))', 'samples(total)'])\n",
    "            myres.iloc[0]['pageview_change_group'] = 'x < 2.5'\n",
    "            myres.iloc[1]['pageview_change_group'] = '2.5 <= x < 4'\n",
    "            myres.iloc[2]['pageview_change_group'] = '4 <= x < 6'\n",
    "            myres.iloc[3]['pageview_change_group'] = 'x >= 6'\n",
    "            rawdata = pd.read_csv('analysis/hold_{}_day/{}_res_win{}.csv'.format(hold, cap, win))\n",
    "            raw_0 = rawdata.loc[rawdata['actual_pageview_in_std'] < 2.5]\n",
    "            raw_1 = rawdata.loc[(rawdata['actual_pageview_in_std'] < 4)&(rawdata['actual_pageview_in_std'] >= 2.5)]\n",
    "            raw_2 = rawdata.loc[(rawdata['actual_pageview_in_std'] < 6)&(rawdata['actual_pageview_in_std'] >= 4)]\n",
    "            raw_3 = rawdata.loc[rawdata['actual_pageview_in_std'] >= 6]\n",
    "            myres.iloc[0, 5] = raw_0.shape[0]\n",
    "            myres.iloc[1, 5] = raw_1.shape[0]\n",
    "            myres.iloc[2, 5] = raw_2.shape[0]\n",
    "            myres.iloc[3, 5] = raw_3.shape[0]\n",
    "            raw = dict()\n",
    "            raw[0] = raw_0\n",
    "            raw[1] = raw_1\n",
    "            raw[2] = raw_2\n",
    "            raw[3] = raw_3\n",
    "            for i in range(4):\n",
    "                temp1 = raw[i].loc[raw[i]['pct_change(%)'] < -1]\n",
    "                total = raw[i].shape[0] + 0.00001\n",
    "                myres.iloc[i, 1] = (temp1.shape[0]/total)*100\n",
    "                temp2 = raw[i].loc[(raw[i]['pct_change(%)'] >= -1)&(raw[i]['pct_change(%)'] < 0)]\n",
    "                myres.iloc[i, 2] = (temp2.shape[0]/total)*100\n",
    "                temp3 = raw[i].loc[(raw[i]['pct_change(%)'] >= 0)&(raw[i]['pct_change(%)'] < 1)]\n",
    "                myres.iloc[i, 3] = (temp3.shape[0]/total)*100\n",
    "                temp4 = raw[i].loc[raw[i]['pct_change(%)'] >= 1]\n",
    "                myres.iloc[i, 4] = (temp4.shape[0]/total)*100\n",
    "            if not os.path.exists(os.path.dirname('{}_cap/window_{}_day/hold_{}_day_statistics/'.format(cap, win, hold))):\n",
    "                os.makedirs(os.path.dirname('{}_cap/window_{}_day/hold_{}_day_statistics/'.format(cap, win, hold)))\n",
    "            myres.to_csv('{}_cap/window_{}_day/hold_{}_day_statistics/statistics_{}_cap_window_{}_hold_{}.csv'.format(cap, win, hold, cap, win, hold), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization, scatter plot\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "for win in [1, 3]:#should include 1,3\n",
    "    for cap in ['small', 'large', 'mid']:\n",
    "        for hold in [1, '1b', 3]:#should include 1, 3\n",
    "            #if win == 1 and (hold == 1 or hold == '1b'):\n",
    "                #continue\n",
    "            rawdata = pd.read_csv('analysis/hold_{}_day/{}_res_win{}.csv'.format(hold, cap, win))\n",
    "            trace = go.Scatter(\n",
    "                x = rawdata['actual_pageview_in_std'],\n",
    "                y = rawdata['pct_change(%)'],\n",
    "                mode = 'markers'\n",
    "            )\n",
    "            data = [trace]\n",
    "            layout = go.Layout(\n",
    "                autosize=True,\n",
    "                title='Scatter plot for trading stocks of 2018',\n",
    "                xaxis = dict(\n",
    "                    title = 'actual_pageview_in_std',\n",
    "                    ticklen= 5\n",
    "                ),\n",
    "                yaxis = dict(\n",
    "                    \n",
    "                    title = 'pct_change(%)',\n",
    "                    ticklen= 5\n",
    "                )\n",
    "            )\n",
    "            fig = go.Figure(data=data, layout=layout)\n",
    "            url = plotly.offline.plot(fig, filename= \\\n",
    "                                      '{}_cap/window_{}_day/hold_{}_day_statistics/scatter_plot_{}_cap_window_{}_hold_{}.html'.format(cap, win, hold, cap, win, hold), auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = pd.read_csv('sample_data_SMA/sma_sentiment_equities.csv')\n",
    "sse = sse[['Date', 'Symbol', 's-score', 's', 's-mean']]\n",
    "sse.columns = ['win_end', 'symbol', 's-score', 's', 's-mean']\n",
    "for hold in [1, '1b', '3']:\n",
    "    for cap in ['small', 'mid', 'large']:\n",
    "        for win in [1, 3]:\n",
    "            ds = pd.read_csv('detail_summary/hold_{}_day/{}_cap_window_{}_detail_summary.csv'.format(hold, cap, win))\n",
    "            ds = ds.merge(sse, on = ['win_end', 'symbol'])\n",
    "            ds.to_csv('detail_summary/hold_{}_day/{}_cap_window_{}_detail_summary.csv'.\\\n",
    "                      format(hold, cap, win), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_senti = pd.read_csv('sample_data_SMA/sma_sentiment_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>raw-s</th>\n",
       "      <th>raw-s-mean</th>\n",
       "      <th>raw-volatility</th>\n",
       "      <th>raw-score</th>\n",
       "      <th>s</th>\n",
       "      <th>s-mean</th>\n",
       "      <th>s-volatility</th>\n",
       "      <th>s-score</th>\n",
       "      <th>s-volume</th>\n",
       "      <th>sv-mean</th>\n",
       "      <th>sv-volatility</th>\n",
       "      <th>sv-score</th>\n",
       "      <th>dispersion</th>\n",
       "      <th>s-buzz</th>\n",
       "      <th>s-delta</th>\n",
       "      <th>center-date</th>\n",
       "      <th>center-time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BroadMktIndex</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>2.448</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.507</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>1.342</td>\n",
       "      <td>0.528</td>\n",
       "      <td>167</td>\n",
       "      <td>302.376</td>\n",
       "      <td>136.874</td>\n",
       "      <td>-0.989</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>1/21/17</td>\n",
       "      <td>15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DJIA</td>\n",
       "      <td>-0.232</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.296</td>\n",
       "      <td>31</td>\n",
       "      <td>82.408</td>\n",
       "      <td>49.258</td>\n",
       "      <td>-1.044</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.391</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>1/21/17</td>\n",
       "      <td>15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDX</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.164</td>\n",
       "      <td>-0.442</td>\n",
       "      <td>12</td>\n",
       "      <td>17.007</td>\n",
       "      <td>8.224</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1/21/17</td>\n",
       "      <td>15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPX</td>\n",
       "      <td>0.484</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>1.819</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.549</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.611</td>\n",
       "      <td>143</td>\n",
       "      <td>237.903</td>\n",
       "      <td>102.941</td>\n",
       "      <td>-0.922</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>1/21/17</td>\n",
       "      <td>15:40:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BroadMktIndex</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>2.431</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>1.322</td>\n",
       "      <td>0.006</td>\n",
       "      <td>121</td>\n",
       "      <td>308.284</td>\n",
       "      <td>134.280</td>\n",
       "      <td>-1.395</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.179</td>\n",
       "      <td>1/22/17</td>\n",
       "      <td>15:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ticker  raw-s  raw-s-mean  raw-volatility  raw-score      s  s-mean  \\\n",
       "0  BroadMktIndex  0.318      -0.505           2.448      0.336  0.507  -0.203   \n",
       "1           DJIA -0.232      -0.427           1.017      0.192 -0.065  -0.229   \n",
       "2            NDX -0.124       0.053           0.341     -0.518 -0.050   0.022   \n",
       "3            SPX  0.484      -0.311           1.819      0.437  0.549  -0.065   \n",
       "4  BroadMktIndex -0.723      -0.577           2.431     -0.060 -0.252  -0.259   \n",
       "\n",
       "   s-volatility  s-score  s-volume  sv-mean  sv-volatility  sv-score  \\\n",
       "0         1.342    0.528       167  302.376        136.874    -0.989   \n",
       "1         0.555    0.296        31   82.408         49.258    -1.044   \n",
       "2         0.164   -0.442        12   17.007          8.224    -0.609   \n",
       "3         1.007    0.611       143  237.903        102.941    -0.922   \n",
       "4         1.322    0.006       121  308.284        134.280    -1.395   \n",
       "\n",
       "   dispersion  s-buzz  s-delta center-date center-time  \n",
       "0       0.557   0.400   -0.086     1/21/17    15:40:00  \n",
       "1       0.710   0.391   -0.104     1/21/17    15:40:00  \n",
       "2       0.750   0.472    0.008     1/21/17    15:40:00  \n",
       "3       0.587   0.411   -0.074     1/21/17    15:40:00  \n",
       "4       0.562   0.437    0.179     1/22/17    15:40:00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_senti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_senti = index_senti.loc[index_senti['ticker'] == 'SPX'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_senti.rename(columns = {'ticker' : 'symbol', 'center-date' : 'date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_senti = sp_senti[['symbol', 'date', 's-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_senti['date'] = pd.to_datetime(sp_senti['date'], format = '%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_senti['date'] = sp_senti['date'].apply(str)\n",
    "sp_senti['date'] = sp_senti['date'].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_url = 'https://ondemand.websol.barchart.com/getHistory.csv?apikey=ondemand&symbol=$SPX&type=daily&startDate=2018-01-01&endDate=2018-12-31&maxRecords=1000&order=asc&sessionFilter=EFK&splits=true&volume=sum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_hist = pd.read_csv(spx_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_hist = spx_hist[['symbol', 'tradingDay', 'open', 'close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx_hist.columns = ['symbol', 'date', 'open', 'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ds[['win_start']]\n",
    "temp.columns = ['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = temp.merge(sp_senti, on = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get business days\n",
    "from pandas.tseries.offsets import *\n",
    "daterange1 = pd.date_range('2017-12-01', '2019-01-20', freq=BDay())\n",
    "daterange1 = list(daterange1.strftime('%Y-%m-%d'))\n",
    "holidays = ['2017-12-25', '2018-01-01', '2018-01-15', '2018-02-19', '2018-03-30', '2018-05-28', '2018-07-04', '2018-09-03',\\\n",
    "            '2018-11-22', '2018-12-05', '2018-12-25', '2019-01-01']\n",
    "for each in holidays:\n",
    "    if each in daterange1:\n",
    "        daterange1.remove(each)\n",
    "daterange2 = daterange1[20:271]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(res.shape[0]):\n",
    "    trading_day = daterange2[daterange2.index(res.loc[i, 'date']) + 1]\n",
    "    res.loc[i, 'buy_date/short_date'] = trading_day\n",
    "    res.loc[i, 'sell_date/close_date'] = trading_day\n",
    "    res.loc[i, 'long_price/short_price'] = float(spx_hist.loc[spx_hist['date'] == trading_day, 'open'])\n",
    "    res.loc[i, 'sell_price/close_price'] = float(spx_hist.loc[spx_hist['date'] == trading_day, 'close'])\n",
    "    res.loc[i, 'pct_change(%)'] = (float(spx_hist.loc[spx_hist['date'] == trading_day, 'close'])/\\\n",
    "                                   float(spx_hist.loc[spx_hist['date'] == trading_day, 'open']) - 1)*100\n",
    "    if res.loc[i, 's-score'] > 1:\n",
    "        res.loc[i, 'position'] = 'long'\n",
    "        res.loc[i, 'p&l'] = res.loc[i, 'sell_price/close_price'] - res.loc[i, 'long_price/short_price']\n",
    "    elif res.loc[i, 's-score'] < -1:\n",
    "        res.loc[i, 'position'] = 'short'\n",
    "        res.loc[i, 'p&l'] = res.loc[i, 'long_price/short_price'] - res.loc[i, 'sell_price/close_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>s-score</th>\n",
       "      <th>buy_date/short_date</th>\n",
       "      <th>sell_date/close_date</th>\n",
       "      <th>long_price/short_price</th>\n",
       "      <th>sell_price/close_price</th>\n",
       "      <th>pct_change(%)</th>\n",
       "      <th>position</th>\n",
       "      <th>p&amp;l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>SPX</td>\n",
       "      <td>2.056</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>2719.31</td>\n",
       "      <td>2723.99</td>\n",
       "      <td>0.172102</td>\n",
       "      <td>long</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>SPX</td>\n",
       "      <td>1.177</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>2018-01-10</td>\n",
       "      <td>2745.55</td>\n",
       "      <td>2748.23</td>\n",
       "      <td>0.097613</td>\n",
       "      <td>long</td>\n",
       "      <td>2.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>2018-03-14</td>\n",
       "      <td>2774.06</td>\n",
       "      <td>2749.48</td>\n",
       "      <td>-0.886066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-03</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2018-04-04</td>\n",
       "      <td>2584.04</td>\n",
       "      <td>2644.69</td>\n",
       "      <td>2.347100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-16</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-0.188</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>2719.71</td>\n",
       "      <td>2720.13</td>\n",
       "      <td>0.015443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-05-17</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-0.382</td>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>2018-05-18</td>\n",
       "      <td>2717.35</td>\n",
       "      <td>2712.97</td>\n",
       "      <td>-0.161186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>SPX</td>\n",
       "      <td>1.062</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>2713.98</td>\n",
       "      <td>2733.29</td>\n",
       "      <td>0.711501</td>\n",
       "      <td>long</td>\n",
       "      <td>19.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-06-06</td>\n",
       "      <td>SPX</td>\n",
       "      <td>1.215</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>2018-06-07</td>\n",
       "      <td>2774.84</td>\n",
       "      <td>2770.37</td>\n",
       "      <td>-0.161090</td>\n",
       "      <td>long</td>\n",
       "      <td>-4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-3.277</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>2698.69</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>0.652909</td>\n",
       "      <td>short</td>\n",
       "      <td>-17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-3.277</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>2018-06-28</td>\n",
       "      <td>2698.69</td>\n",
       "      <td>2716.31</td>\n",
       "      <td>0.652909</td>\n",
       "      <td>short</td>\n",
       "      <td>-17.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>2896.85</td>\n",
       "      <td>2904.18</td>\n",
       "      <td>0.253033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>SPX</td>\n",
       "      <td>-1.604</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>2018-11-13</td>\n",
       "      <td>2730.05</td>\n",
       "      <td>2722.18</td>\n",
       "      <td>-0.288273</td>\n",
       "      <td>short</td>\n",
       "      <td>7.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date symbol  s-score buy_date/short_date sell_date/close_date  \\\n",
       "0   2018-01-03    SPX    2.056          2018-01-04           2018-01-04   \n",
       "1   2018-01-09    SPX    1.177          2018-01-10           2018-01-10   \n",
       "2   2018-03-13    SPX   -0.056          2018-03-14           2018-03-14   \n",
       "3   2018-04-03    SPX   -0.419          2018-04-04           2018-04-04   \n",
       "4   2018-05-16    SPX   -0.188          2018-05-17           2018-05-17   \n",
       "5   2018-05-17    SPX   -0.382          2018-05-18           2018-05-18   \n",
       "6   2018-05-22    SPX    1.062          2018-05-23           2018-05-23   \n",
       "7   2018-06-06    SPX    1.215          2018-06-07           2018-06-07   \n",
       "8   2018-06-27    SPX   -3.277          2018-06-28           2018-06-28   \n",
       "9   2018-06-27    SPX   -3.277          2018-06-28           2018-06-28   \n",
       "10  2018-09-12    SPX   -0.020          2018-09-13           2018-09-13   \n",
       "11  2018-11-12    SPX   -1.604          2018-11-13           2018-11-13   \n",
       "\n",
       "    long_price/short_price  sell_price/close_price  pct_change(%) position  \\\n",
       "0                  2719.31                 2723.99       0.172102     long   \n",
       "1                  2745.55                 2748.23       0.097613     long   \n",
       "2                  2774.06                 2749.48      -0.886066      NaN   \n",
       "3                  2584.04                 2644.69       2.347100      NaN   \n",
       "4                  2719.71                 2720.13       0.015443      NaN   \n",
       "5                  2717.35                 2712.97      -0.161186      NaN   \n",
       "6                  2713.98                 2733.29       0.711501     long   \n",
       "7                  2774.84                 2770.37      -0.161090     long   \n",
       "8                  2698.69                 2716.31       0.652909    short   \n",
       "9                  2698.69                 2716.31       0.652909    short   \n",
       "10                 2896.85                 2904.18       0.253033      NaN   \n",
       "11                 2730.05                 2722.18      -0.288273    short   \n",
       "\n",
       "      p&l  \n",
       "0    4.68  \n",
       "1    2.68  \n",
       "2     NaN  \n",
       "3     NaN  \n",
       "4     NaN  \n",
       "5     NaN  \n",
       "6   19.31  \n",
       "7   -4.47  \n",
       "8  -17.62  \n",
       "9  -17.62  \n",
       "10    NaN  \n",
       "11   7.87  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly\n",
    "#import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019-04-26 sp500&long_hold1day_analysis\n",
    "res.to_csv('2019-04-26 sp500&long_hold1day_analysis/sp500_backtest.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
